{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382b7c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Text, Button, Label, messagebox\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d463f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercasing(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "    return text\n",
    "\n",
    "def data_deidentification(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'@\\w+\\:?', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'#\\w+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_urls(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'https?://\\S+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'\\d+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'\\s+', ' ', text.strip())\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def contraction_expansion(text):\n",
    "    contractions = { \n",
    "        \"won't\": \"will not\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"what's\": \"what is\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"%\": \" percent\",\n",
    "        \"that's\": \"that is\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"he's\": \"he is\",\n",
    "        \"she's\": \"she is\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"n't\": \" not\",\n",
    "        \"'ve\": \" have\",\n",
    "        \"'s\": \" is\",\n",
    "        \"â€™s\": \"\",\n",
    "        \"'re\": \" are\",\n",
    "        \"'d\": \" would\",\n",
    "        \"'ll\": \" will\",\n",
    "        \"'m\": \" am\"\n",
    "    }\n",
    "    for contraction, replacement in contractions.items(): \n",
    "        text = text.replace(contraction, replacement)\n",
    "    return text\n",
    "\n",
    "def punctuations_and_abbreviations(text):\n",
    "    library = [\n",
    "        (r\"w/\", \" with \"),\n",
    "        (r\"w/o\", \"without\"),\n",
    "        (r\"(\\d+)(k)\", r\"\\g<1>000\"),\n",
    "        (r\":\", \" : \"),\n",
    "        (r\" u s \", \" american \"),\n",
    "        (r\"\\0s\", \"0\"),\n",
    "        (r\" 9 11 \", \"911\"),\n",
    "        (r\"e - mail\", \"email\"),\n",
    "        (r\"j k\", \"jk\"),\n",
    "        (r\"\\s{2,}\", \" \"),\n",
    "        (r\"amp;\", \"and\"),\n",
    "        (r\"g2g\", \"gtg\"),\n",
    "        (r\"2moro\", \"tomorrow\"),\n",
    "        (r\"b4\", \"before\"),\n",
    "        (r\"2nite\", \"tonight\"),\n",
    "        (r\"2day\", \"today\"),\n",
    "        (r\"4U\", \"for you\"),\n",
    "        (r\"4get\", \"forget\"),\n",
    "        (r\"2morrow\", \"tomorrow\"),\n",
    "        (r\"2be\", \"because\"),\n",
    "        (r\"l8r\", \"later\"),\n",
    "        (r\",\", \" \"),\n",
    "        (r\"\\.\", \" \"),\n",
    "        (r\"!\", \" \"),\n",
    "        (r\";\", \" \"),\n",
    "        (r\"-\", \" \"),\n",
    "        (r\":\", \" \"),\n",
    "        (r\"\\/\", \" \"),\n",
    "        (r\"%\", \" \"),\n",
    "        (r\"&\", \" \"),\n",
    "        (r\"\\^\", \" ^ \"),\n",
    "        (r\"\\+\", \" + \"),\n",
    "        (r\"\\-\", \" - \"),\n",
    "        (r\"\\=\", \" = \"),\n",
    "        (r\"[^A-Za-z0-9^,!.\\/+-=]\", \" \"), \n",
    "    ]\n",
    "    for pattern, replacement in library:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    return text\n",
    "def name_removal(text):\n",
    "    candidate = {\n",
    "    #presidential candidates\n",
    "    \"president\": \" \",\n",
    "    \"rodrigo\": \" \",\n",
    "    \"'roa\": \" \",\n",
    "    \"duterte\": \" \",\n",
    "    \"du30\": \" \", #du30 \n",
    "    \"prrd\": \" \", \n",
    "    \"rody\": \" \",\n",
    "    \"digong\": \" \",\n",
    "    \"binay\": \" \", \n",
    "    \"jojo\": \" \",\n",
    "    \"jejo\": \" \",\n",
    "    \"jejomar\": \" \",\n",
    "    \"b1nay\": \" \",  #b1nay\n",
    "    \"mar\": \" \", \n",
    "    \"roxas\": \" \",\n",
    "    \"grace\": \" \",\n",
    "    \"poe\": \" \",\n",
    "    \"miriam\": \" \",\n",
    "    \"defensor\": \" \",\n",
    "    \"santiago\": \" \",\n",
    "    #vice presidential candidates\n",
    "    \"alan\": \" \", \n",
    "    \"peter\": \" \", \n",
    "    \"cayetano\": \" \", \n",
    "    \"apc\": \" \", #abbreviation for alan peter cayetano\n",
    "    \"leni\": \" \",    \n",
    "    \"robredo\": \" \",\n",
    "    \"francis\": \" \",\n",
    "    \"escudero\": \" \", \n",
    "    \"chiz\": \" \", \n",
    "    \"honasan\": \" \", \n",
    "    \"gringo\": \" \", \n",
    "    \"gregorio\": \" \",\n",
    "    \"bongbong\": \" \",\n",
    "    \"ferdinand\": \" \",\n",
    "    \"marcos\": \" \",\n",
    "    \"bbm\": \" \",\n",
    "    \"antonio\": \" \",\n",
    "    \"trillanes\": \" \",\n",
    "    \"vice\": \" \", \n",
    "    \"vp\": \" \",\n",
    "    \"villar\": \" \",\n",
    "    \"erap\" : \" \",\n",
    "    \"alma\" : \" \",\n",
    "    \"moreno\": \" \",\n",
    "    \"djp\": \" \",\n",
    "    \"senator\": \" \",\n",
    "    \"daniel\": \" \",\n",
    "    \"padilla\": \" \",\n",
    "    \"abi\": \" \",\n",
    "    \"abby\": \" \",\n",
    "    \"zapanta\": \" \",\n",
    "    \"mds\": \" \",\n",
    "    }\n",
    "    # Replace candidate names\n",
    "    for name, replacement in candidate.items():\n",
    "        text = re.sub(r'\\b' + re.escape(name) + r'\\b', replacement, text)\n",
    "    return text\n",
    "\n",
    "def remove_rt_and_single_char(text):\n",
    "    if isinstance(text, str):\n",
    "        pattern = r'\\brt\\b|\\b[a-z]\\b'\n",
    "        return re.sub(pattern, '', text.strip())\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "    \n",
    "model_1 = joblib.load(\"DT.pkl\")\n",
    "model_2 = joblib.load(\"KNN.pkl\")   \n",
    "model_3 = joblib.load(\"GNB.pkl\")   \n",
    "model_4 = joblib.load(\"SVM.pkl\")   \n",
    "meta_model = joblib.load(\"LR-metamodel.pkl\")   \n",
    "tfidf_vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")   \n",
    "    \n",
    "    \n",
    "\n",
    "def classify_text(event=None):\n",
    "    input_text = text_input.get(\"1.0\", \"end-1c\")\n",
    "    if input_text:\n",
    "        # Preprocess the input text\n",
    "        preprocessed_text = lowercasing(input_text)\n",
    "        preprocessed_text = remove_hashtags(preprocessed_text)\n",
    "        preprocessed_text = remove_urls(preprocessed_text)\n",
    "        preprocessed_text = remove_numbers(preprocessed_text)\n",
    "        preprocessed_text = remove_extra_spaces(preprocessed_text)\n",
    "        preprocessed_text = contraction_expansion(preprocessed_text)\n",
    "        preprocessed_text = punctuations_and_abbreviations(preprocessed_text)\n",
    "        preprocessed_text = name_removal(preprocessed_text)\n",
    "        preprocessed_text = remove_rt_and_single_char(preprocessed_text)\n",
    "        \n",
    "        if not preprocessed_text.strip():\n",
    "            messagebox.showwarning(\"Warning\", \"Please enter text for analysis\")\n",
    "            return\n",
    "        \n",
    "        # TF-IDF Vectorization for the preprocessed text\n",
    "        input_tfidf = tfidf_vectorizer.transform([preprocessed_text])\n",
    "        input_df = pd.DataFrame(input_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "        \n",
    "        # Make predictions using base models\n",
    "        input_pred_1 = model_1.predict(input_df)\n",
    "        input_pred_2 = model_2.predict(input_df)\n",
    "        input_pred_3 = model_3.predict(input_df)\n",
    "        input_pred_4 = model_4.predict(input_df)\n",
    "        \n",
    "        # Display predictions of base models\n",
    "        base_model_results = f\"DT: {'Hate' if input_pred_1[0] else 'Not Hate'}\\n\" + \\\n",
    "                             f\"KNN: {'Hate' if input_pred_2[0] else 'Not Hate'}\\n\" + \\\n",
    "                             f\"GNB: {'Hate' if input_pred_3[0] else 'Not Hate'}\\n\" + \\\n",
    "                             f\"SVM: {'Hate' if input_pred_4[0] else 'Not Hate'}\\n\"\n",
    "        result_label.config(text=base_model_results)\n",
    "        \n",
    "        input_blend = pd.concat([input_df, \n",
    "                                 pd.DataFrame(input_pred_1), \n",
    "                                 pd.DataFrame(input_pred_2), \n",
    "                                 pd.DataFrame(input_pred_3), \n",
    "                                 pd.DataFrame(input_pred_4)], axis=1)\n",
    "        input_blend.reset_index(drop=True, inplace=True)\n",
    "        # Make predictions using the meta-model\n",
    "        meta_pred = meta_model.predict(input_blend.values)\n",
    "        \n",
    "        # Display final classification result\n",
    "        final_result = f\"LR Metamodel : {'Hate' if meta_pred[0] else 'Not Hate'}\"\n",
    "        result_label.config(text=result_label.cget(\"text\") + \"\\n\\n\" + final_result)\n",
    "        \n",
    "    else:\n",
    "        messagebox.showwarning(\"Warning\", \"Please enter text for analysis\")\n",
    "\n",
    "\n",
    "# Create GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Hate Detector GUI\")\n",
    "\n",
    "# Text Input\n",
    "text_input_label = Label(root, text=\"Enter Text:\", font=(\"Helvetica\", 18))  # Adjust font size here\n",
    "text_input_label.pack()\n",
    "text_input = Text(root, height=20, width=70, font=(\"Helvetica\", 20), wrap=\"word\") \n",
    "text_input.pack()\n",
    "\n",
    "# Analyze Button\n",
    "analyze_button = Button(root, text=\"Analyze\", command=classify_text, font=(\"Helvetica\", 15))  # Adjust font size here\n",
    "analyze_button.pack()\n",
    "\n",
    "# Result Label\n",
    "result_label = Label(root, text=\"Base Model Predictions:\", font=(\"Helvetica\", 18))  # Adjust font size here\n",
    "result_label.pack()\n",
    "\n",
    "def on_enter(event):\n",
    "    classify_text()\n",
    "    return 'break'\n",
    "root.bind('<Return>', classify_text)\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvthesis",
   "language": "python",
   "name": "venvthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
