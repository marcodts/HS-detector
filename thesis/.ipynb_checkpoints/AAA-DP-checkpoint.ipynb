{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6666838-19ac-449e-a520-29deba50d92f",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032e9a9-2d9a-4cba-a91a-cf16977f32b3",
   "metadata": {},
   "source": [
    "# <span style=\"color:purple\">IMPORT LIBRARIES: ```</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb0dc4-056b-4858-9edd-6e2cc07c5a79",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e89c807-ed95-4807-93b8-db4c1ff23761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b4d98-0213-4f91-a97a-e559a595bf4c",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <span style=\"color:purple\">IMPORT DATASET: ```</span>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5656e059-ddb2-4cf1-a5c5-883f1b4f3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Thesis Datasets - Combined Total (Labeled).csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a45e07-6470-49ff-a0bc-a75bff9957d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #insert dataset\n",
    "# dataset = \"combinedV5\"\n",
    "\n",
    "# data = pd.read_csv(dataset+\".csv\",  )\n",
    "# #print(data['text'][:5])\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269ebf7-7b23-4a67-a2f4-8c0d4e530716",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------\n",
    "## <span style=\"color:purple\">DATASET Overview & Checking for NULL and DUPLICATE values ```</span>\n",
    "### -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1903cd84-534d-47da-b4f6-8d1c4c6d20b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10199\n",
      "1     8685\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GASTOS NI VP BINAY SA POLITICAL ADS HALOS P7-M NA Inaasahan na ni Vice President Jejomar Binay na may mga taong... https://t.co/SDytgbWiLh</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA NGA DI STRAIGHT</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salamat sa walang sawang suporta ng mga taga makati! Ang Pagbabalik Binay In Makati #OnlyBinayInMakatiSanKaPa https://t.co/iwAOdtZPRE</td>\n",
       "      <td>0</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@rapplerdotcom putangina mo binay TAKBO PA</td>\n",
       "      <td>1</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binay with selective amnesia, forgetting about the past six years he spent preparing to be president.  #PiliPinasDebates2016</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18879</th>\n",
       "      <td>RT @PinkSapph: If a hoe is talking to your man, she's not the problem, he is. The fact that hoes feel welcomed reflects on how he acts behi&amp;#8230;</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18880</th>\n",
       "      <td>@rednexican69 sounds like a bad bitch.</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18881</th>\n",
       "      <td>#5WordsAfterSex is that all pussy bitch?</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18882</th>\n",
       "      <td>I seen Scooby hoe some niggas at the gardens too &amp;#128514;&amp;#128514;&amp;#128514;</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18883</th>\n",
       "      <td>RT @Taste_SweetTay: This bitch just blew my high &amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18884 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                     text  \\\n",
       "0              GASTOS NI VP BINAY SA POLITICAL ADS HALOS P7-M NA Inaasahan na ni Vice President Jejomar Binay na may mga taong... https://t.co/SDytgbWiLh   \n",
       "1                                                                                          Mar Roxas TANG INA TUWID NA DAAN DAW .. EH SYA NGA DI STRAIGHT   \n",
       "2                   Salamat sa walang sawang suporta ng mga taga makati! Ang Pagbabalik Binay In Makati #OnlyBinayInMakatiSanKaPa https://t.co/iwAOdtZPRE   \n",
       "3                                                                                                              @rapplerdotcom putangina mo binay TAKBO PA   \n",
       "4                            Binay with selective amnesia, forgetting about the past six years he spent preparing to be president.  #PiliPinasDebates2016   \n",
       "...                                                                                                                                                   ...   \n",
       "18879  RT @PinkSapph: If a hoe is talking to your man, she's not the problem, he is. The fact that hoes feel welcomed reflects on how he acts behi&#8230;   \n",
       "18880                                                                                                              @rednexican69 sounds like a bad bitch.   \n",
       "18881                                                                                                            #5WordsAfterSex is that all pussy bitch?   \n",
       "18882                                                                        I seen Scooby hoe some niggas at the gardens too &#128514;&#128514;&#128514;   \n",
       "18883                                                      RT @Taste_SweetTay: This bitch just blew my high &#128514;&#128514;&#128514;&#128514;&#128514;   \n",
       "\n",
       "       label  language  \n",
       "0          0   English  \n",
       "1          1   English  \n",
       "2          0  Filipino  \n",
       "3          1  Filipino  \n",
       "4          0   English  \n",
       "...      ...       ...  \n",
       "18879      1   English  \n",
       "18880      1   English  \n",
       "18881      1   English  \n",
       "18882      1   English  \n",
       "18883      1   English  \n",
       "\n",
       "[18884 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = data['label'].value_counts()\n",
    "print(label_counts)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb9ad78-a34c-415f-bf37-259c9f5e6b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18884 entries, 0 to 18883\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      18884 non-null  object\n",
      " 1   label     18884 non-null  int64 \n",
      " 2   language  18884 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 442.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#DATASET OVERVIEW\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48f093c3-6f0a-4ea7-af05-bb93377a4c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label, language]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK FOR NULL VALUES\n",
    "data.isnull().sum()\n",
    "null_rows = data[data['label'].isnull()]\n",
    "\n",
    "null_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847ae30e-25fa-45a6-8b36-dbc409486ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK FOR DUPLICATE VALUES\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d081736-b61b-4200-9bd8-e5ec1850055c",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>Dropping Duplicates and NULL</font>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747afc44-fe23-429b-8c00-d2cbb610bac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>wag magsawa dahil hndi mag sasawa si VP Binay Only B1NAY #OnlyBinayWinner</td>\n",
       "      <td>0</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8606</th>\n",
       "      <td>“Time you enjoy wasting is not wasted time.” Ang Pagbabalik Binay In Makati #OnlyBinayInMakatiSanKaPa</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12186</th>\n",
       "      <td>President: Rody Duterte VPresident: Bongbong Marcos Secretary: Miriam Santiago CLEANERS: Mar Roxas &amp;amp; Jejomar Binay ??? #HalalanResults</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12783</th>\n",
       "      <td>OFW rights’ advocate Toots Ople agrees to be a guest candidate of UNA, completing VP Binay’s Senate slate. #PHvote</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12892</th>\n",
       "      <td>Bakit ba si Binay, lagi nya sinasabi nung mayor sya \"sa Makati..sa Makati\" .. bakit wala syang maipagmalaki bilang bise presidente? Ano na</td>\n",
       "      <td>0</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13963</th>\n",
       "      <td>Toni: \"Ano ang katangian niyo kung kaya't dapat kayong maging Big Winner?\" Binay: \"Nognog, pandak, at laki sa hirap.\"</td>\n",
       "      <td>0</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14095</th>\n",
       "      <td>Partial and unofficial tally of PPCRV: Duterte - 9,990 Roxas - 8,711 Poe - 7,543 Binay - 5,250 Santiago - 1,096</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             text  \\\n",
       "5129                                                                    wag magsawa dahil hndi mag sasawa si VP Binay Only B1NAY #OnlyBinayWinner   \n",
       "8606                                        “Time you enjoy wasting is not wasted time.” Ang Pagbabalik Binay In Makati #OnlyBinayInMakatiSanKaPa   \n",
       "12186  President: Rody Duterte VPresident: Bongbong Marcos Secretary: Miriam Santiago CLEANERS: Mar Roxas &amp; Jejomar Binay ??? #HalalanResults   \n",
       "12783                          OFW rights’ advocate Toots Ople agrees to be a guest candidate of UNA, completing VP Binay’s Senate slate. #PHvote   \n",
       "12892  Bakit ba si Binay, lagi nya sinasabi nung mayor sya \"sa Makati..sa Makati\" .. bakit wala syang maipagmalaki bilang bise presidente? Ano na   \n",
       "13963                       Toni: \"Ano ang katangian niyo kung kaya't dapat kayong maging Big Winner?\" Binay: \"Nognog, pandak, at laki sa hirap.\"   \n",
       "14095                             Partial and unofficial tally of PPCRV: Duterte - 9,990 Roxas - 8,711 Poe - 7,543 Binay - 5,250 Santiago - 1,096   \n",
       "\n",
       "       label  language  \n",
       "5129       0  Filipino  \n",
       "8606       0   English  \n",
       "12186      0   English  \n",
       "12783      0   English  \n",
       "12892      0  Filipino  \n",
       "13963      0  Filipino  \n",
       "14095      0   English  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Duplicates\n",
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8579702-411a-4cc9-a862-94405c7b21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicates.\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop null values.\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Reset the index.\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4189afc8-ee34-4ff8-88e0-5824835e5b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if there are still duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f9a0b33-685f-4962-ac82-07495994ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        0\n",
       "label       0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if there are still NULL values\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf47f4e-bd92-48a0-be8e-ac93add621b7",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <span style=\"color:purple\">Data Preprocessing Functions ```</span>\n",
    "## <font color='purple'>``` Functions Overview ```</font>\n",
    "1. **<font color='blue'>Lowercasing</font>**\n",
    "2. **<font color='blue'>Binary Classification</font>**\n",
    "3. **<font color='blue'>Data De-identification</font>**\n",
    "4. **<font color='blue'>Hashtag Removal</font>**\n",
    "5. **<font color='blue'>URL Removal</font>**\n",
    "6. **<font color='blue'>Removing Numbers</font>**\n",
    "7. **<font color='blue'>Removing Extra White Space</font>**\n",
    "8. **<font color='blue'>Contraction Expansion</font>**\n",
    "9. **<font color='blue'>Punctuation Removal</font>**\n",
    "10. **<font color='blue'>Stop Words Removal</font>**\n",
    "11. **<span style=\"color:blue\">Candidate Names and RT String Removal</span>**\n",
    "## -------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c055cef-bb9f-4b70-97c6-732aa317f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercasing\n",
    "def lowercasing(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "    return text\n",
    "\n",
    "#binary classification of Hate Score \n",
    "def binary_classification(num):\n",
    "    if isinstance(num, str):\n",
    "        num = float(num)  # Convert num to float if it's a string\n",
    "    if num >= 0.5:\n",
    "        num = 1\n",
    "    else:\n",
    "        num = 0\n",
    "    return num\n",
    "\n",
    "# Remove Mentions - Data-deidentification\n",
    "def data_deidentification(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'@\\w+\\:?', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'#\\w+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_urls(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'https?://\\S+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'\\d+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'\\s+', ' ', text.strip())\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d897aa2-1037-49ec-a2a9-9604fc5c734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contraction library\n",
    "def contraction_expansion(text):\n",
    "    contractions = { \n",
    "        \"won't\": \"will not\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"what's\": \"what is\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"%\": \" percent\",\n",
    "        \"that's\": \"that is\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"he's\": \"he is\",\n",
    "        \"she's\": \"she is\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"n't\": \" not\",\n",
    "        \"'ve\": \" have\",\n",
    "        \"'s\": \" is\",\n",
    "        \"’s\": \"\",\n",
    "        \"'re\": \" are\",\n",
    "        \"'d\": \" would\",\n",
    "        \"'ll\": \" will\",\n",
    "        \"'m\": \" am\",\n",
    "        \"ako'y\": \"ako ay\"\n",
    "    }\n",
    "    for contraction, replacement in contractions.items(): \n",
    "        text = text.replace(contraction, replacement)\n",
    "    return text\n",
    "    \n",
    "\n",
    "\n",
    "def punctuations_and_abbreviations(text):\n",
    "    library = [\n",
    "        (r\"w/\", \" with \"),\n",
    "        (r\"w/o\", \"without\"),\n",
    "        (r\"(\\d+)(k)\", r\"\\g<1>000\"),\n",
    "        (r\":\", \" : \"),\n",
    "        (r\" u s \", \" american \"),\n",
    "        (r\"\\0s\", \"0\"),\n",
    "        (r\" 9 11 \", \"911\"),\n",
    "        (r\"e - mail\", \"email\"),\n",
    "        (r\"j k\", \"jk\"),\n",
    "        (r\"\\s{2,}\", \" \"),\n",
    "        (r\"amp;\", \"and\"),\n",
    "        (r\",\", \" \"),\n",
    "        (r\"\\.\", \" \"),\n",
    "        (r\"!\", \" \"),\n",
    "        (r\";\", \" \"),\n",
    "        (r\"-\", \" \"),\n",
    "        (r\":\", \" \"),\n",
    "        (r\"\\/\", \" \"),\n",
    "        (r\"%\", \" \"),\n",
    "        (r\"&\", \" \"),\n",
    "        (r\"\\^\", \"  \"),\n",
    "        (r\"\\+\", \"  \"),\n",
    "        (r\"\\-\", \"  \"),\n",
    "        (r\"\\=\", \"  \"),\n",
    "        (r\"https\", \" \"),\n",
    "        (r\"'\", \" \"),\n",
    "        (r\"[^A-Za-z0-9^,!.\\/+-=]\", \" \"), \n",
    "    ]\n",
    "    for pattern, replacement in library:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "#From Filipino Toxic Speech\n",
    "# Built-in English stop words.\n",
    "# english_stop_words = CountVectorizer(stop_words='english').get_stop_words()\n",
    "\n",
    "def custom_stop_words():\n",
    "    custom_stop_words = [\n",
    "        'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and',\n",
    "        'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being',\n",
    "        'below', 'between', 'both', 'but', 'by', 'can', \"can't\", 'cannot', 'could',\n",
    "        \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down',\n",
    "        'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has',\n",
    "        \"hasn't\", 'have', \"haven't\", 'having', 'how', \"how's\",\n",
    "        'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it',\n",
    "        \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my',\n",
    "        'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other',\n",
    "        'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", \n",
    "        'should', \"shouldn't\", 'so', 'some', 'such', 'than',\n",
    "        'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there',\n",
    "        \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this',\n",
    "        'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\",\n",
    "        'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\",\n",
    "        'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom',\n",
    "        'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\"\n",
    "        # filipino_stop_words1    \n",
    "        \"ako\", \"akin\", \"ako'y\", \"amin\", \"aming\", \"ang\", \"ano\", \"anuman\", \"apat\", \"at\", \"atin\", \"ating\",\n",
    "        \"ay\", \"bababa\", \"bago\", \"bakit\", \"bawat\", \"bilang\", \"dahil\", \"dalawa\", \"dapat\", \"din\", \"dito\", \"doon\",\n",
    "        \"gagawin\", \"gayunman\", \"ginagawa\", \"ginawa\", \"ginawang\", \"gumawa\", \"gusto\", \"habang\", \"hanggang\", \"hindi\", \"huwag\", \"iba\",\n",
    "        \"ibaba\", \"ibabaw\", \"ibig\", \"ikaw\", \"ilagay\", \"ilalim\", \"ilan\", \"inyong\", \"isa\", \"isang\", \"ito\", \"iyo\",\n",
    "        \"iyon\", \"iyong\", \"kahit\", \"kailangan\", \"kailanman\", \"kami\", \"kanila\", \"kanilang\", \"kanino\", \"kanya\", \"kanyang\",\n",
    "        \"kapag\", \"kapwa\", \"karamihan\", \"katiyakan\", \"katulad\", \"kay\", \"kaya\", \"kaysa\", \"ko\", \"kung\", \"laban\",\n",
    "        \"lahat\", \"lamang\", \"likod\", \"lima\", \"maaari\", \"maaaring\", \"maging\", \"mahusay\", \"makita\", \"marami\", \"marapat\", \"mga\",\n",
    "        \"minsan\", \"mismo\", \"mula\", \"muli\", \"na\", \"nabanggit\", \"naging\", \"nagkaroon\", \"nais\", \"nakita\", \"namin\", \"napaka\",\n",
    "        \"narito\", \"nasaan\", \"ng\", \"nga\", \"ngayon\", \"ni\", \"nila\", \"nilang\", \"nito\", \"niya\", \"niyang\", \"noon\",\n",
    "        \"o\", \"pag\", \"pala\", \"para\", \"pati\", \"pero\", \"pumunta\", \"pumupunta\", \"sa\", \"saan\", \"sabi\", \"sabihin\",\n",
    "        \"sarili\", \"si\", \"sila\", \"sino\", \"siya\", \"tatlo\", \"tayo\", \"tulad\", \"tungkol\", \"una\", \"walang\",\n",
    "        #filipino_stopwords2 \n",
    "        'ako', 'sa', 'akin', 'ko', 'aking', 'sarili', 'kami', 'atin', 'ang', 'aming', 'amin', 'ating',\n",
    "        'ka', 'iyong', 'iyo', 'inyong', 'siya', 'kanya', 'mismo', 'ito', 'nito', 'kanyang', 'sila', 'nila',\n",
    "        'kanila', 'kanilang', 'kung', 'ano', 'alin', 'sino', 'kanino', 'na', 'mga', 'iyon', 'am', 'ay',\n",
    "        'maging', 'naging', 'mayroon', 'may', 'nagkaroon', 'pagkakaroon', 'gumawa', 'ginagawa', 'ginawa', 'paggawa',\n",
    "        'ibig', 'dapat', 'maaari', 'marapat', 'kong', 'ikaw', 'tayo', 'hindi', 'namin', 'gusto', 'nais',\n",
    "        'niyang', 'nilang', 'niya', 'huwag', 'ginawang', 'gagawin', 'maaaring', 'sabihin', 'narito', 'kapag', 'ni',\n",
    "        'nasaan', 'bakit', 'paano', 'kailangan', 'walang', 'katiyakan', 'isang', 'at', 'pero', 'o', 'dahil',\n",
    "        'bilang', 'hanggang', 'habang', 'ng', 'pamamagitan', 'para', 'tungkol', 'laban', 'pagitan', 'panahon', 'bago',\n",
    "        'pagkatapos', 'itaas', 'ibaba', 'mula', 'pataas', 'pababa', 'palabas', 'ibabaw', 'ilalim', 'muli', 'pa',\n",
    "        'minsan', 'dito', 'doon', 'saan', 'lahat', 'anumang', 'kapwa', 'bawat', 'ilan', 'karamihan', 'iba', 'tulad',\n",
    "        'lamang', 'pareho', 'kaya', 'kaysa', 'masyado', 'napaka', 'isa', 'bababa', 'kulang', 'marami', 'ngayon',\n",
    "        'kailanman', 'sabi', 'nabanggit', 'din', 'kumuha', 'pumunta', 'pumupunta', 'ilagay', 'makita', 'nakita',\n",
    "        'katulad', 'mahusay', 'likod', 'kahit', 'paraan', 'noon', 'gayunman', 'dalawa', 'tatlo', 'apat', 'lima',\n",
    "        'una', 'pangalawa'\n",
    "    ]\n",
    "    return custom_stop_words\n",
    "\n",
    "def remove_custom_stopwords(text):\n",
    "    custom_stopwords = custom_stop_words()\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    # Remove custom stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in custom_stopwords]\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "803b0e89-34e9-4cd6-be36-6a4cfac30840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_removal(text):\n",
    "    candidate = {\n",
    "    #presidential candidates\n",
    "    \"president\": \" \",\n",
    "    \"rodrigo\": \" \",\n",
    "    \"'roa\": \" \",\n",
    "    \"duterte\": \" \",\n",
    "    \"du30\": \" \", #du30 \n",
    "    \"prrd\": \" \", \n",
    "    \"rody\": \" \",\n",
    "    \"digong\": \" \",\n",
    "    \"binay\": \" \", \n",
    "    \"jojo\": \" \",\n",
    "    \"jejo\": \" \",\n",
    "    \"jejomar\": \" \",\n",
    "    \"b1nay\": \" \",  #b1nay\n",
    "    \"mar\": \" \", \n",
    "    \"roxas\": \" \",\n",
    "    \"grace\": \" \",\n",
    "    \"poe\": \" \",\n",
    "    \"miriam\": \" \",\n",
    "    \"defensor\": \" \",\n",
    "    \"santiago\": \" \",\n",
    "    #vice presidential candidates\n",
    "    \"alan\": \" \", \n",
    "    \"peter\": \" \", \n",
    "    \"cayetano\": \" \", \n",
    "    \"apc\": \" \", #abbreviation for alan peter cayetano\n",
    "    \"leni\": \" \",    \n",
    "    \"robredo\": \" \",\n",
    "    \"francis\": \" \",\n",
    "    \"escudero\": \" \", \n",
    "    \"chiz\": \" \", \n",
    "    \"honasan\": \" \", \n",
    "    \"gringo\": \" \", \n",
    "    \"gregorio\": \" \",\n",
    "    \"bongbong\": \" \",\n",
    "    \"ferdinand\": \" \",\n",
    "    \"marcos\": \" \",\n",
    "    \"bbm\": \" \",\n",
    "    \"antonio\": \" \",\n",
    "    \"trillanes\": \" \",\n",
    "    \"vice\": \" \", \n",
    "    \"vp\": \" \",\n",
    "    \"villar\": \" \",\n",
    "    \"erap\" : \" \",\n",
    "    \"alma\" : \" \",\n",
    "    \"moreno\": \" \",\n",
    "    \"djp\": \" \",\n",
    "    \"senator\": \" \",\n",
    "    \"daniel\": \" \",\n",
    "    \"padilla\": \" \",\n",
    "    \"abi\": \" \",\n",
    "    \"abby\": \" \",\n",
    "    \"zapanta\": \" \",\n",
    "    \"mds\": \" \",\n",
    "    }\n",
    "    # Replace candidate names\n",
    "    for name, replacement in candidate.items():\n",
    "        text = re.sub(r'\\b' + re.escape(name) + r'\\b', replacement, text)\n",
    "    return text\n",
    "\n",
    "def remove_rt(text):\n",
    "    if isinstance(text, str):\n",
    "        pattern = r'\\brt\\b|\\b[a-z]\\b'\n",
    "        return re.sub(pattern, '', text.strip())\n",
    "    else:\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36399685-d27b-4e94-824c-45711ad7842c",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>Applying Preprocessing to Data</font>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d69523b7-c461-4489-84e7-b3187c90358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['text'] = data['text'].apply(remove_extra_spaces)\n",
    "#data\n",
    "#data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1a59b91-2a91-4798-89d9-a281e482758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample text: \n",
    "#@jejomarbinay Sana ako na lang yung napili sa THE VOICE      #thevoice. DUTERTE and CAYETANO WON! it's 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(lowercasing)\n",
    "# @jejomarbinay sana ako na lang yung napili sa the voice      #thevoice. duterte won! it's 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(remove_extra_spaces)\n",
    "# sana ako na lang yung napili sa the voice #thevoice. duterte and cayetano won! it's 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(data_deidentification)\n",
    "# sana ako na lang yung napili sa the voice #thevoice. duterte and cayetano won! it's 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(contraction_expansion)\n",
    "# sana ako na lang yung napili sa the voice #thevoice. duterte and cayetano won! it is 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(name_removal)\n",
    "# sana ako na lang yung napili sa the voice #thevoice. won! it is 100% unfair voting ... https://debololo.com\n",
    "\n",
    "\n",
    "\n",
    "data['text'] = data['text'].apply(remove_hashtags)\n",
    "# sana ako na lang yung napili sa the voice. won! it is 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(remove_urls)\n",
    "# sana ako na lang yung napili sa the voice. won! it is 100% unfair voting ...\n",
    "\n",
    "data['text'] = data['text'].apply(punctuations_and_abbreviations)\n",
    "# sana ako na lang yung napili sa the voice won it is 100 unfair voting\n",
    "\n",
    "data['text'] = data['text'].apply(remove_numbers)\n",
    "# sana ako na lang yung napili sa the voice. won! it is unfair voting ...\n",
    "\n",
    "# data['text'] = data['text'].apply(remove_custom_stopwords)\n",
    "\n",
    "# sana lang yung napili voice. won unfair voting\n",
    "\n",
    "data['label'] = data['label'].apply(binary_classification)\n",
    "# Assuming hate label for the sample text is 0.3, it is converted to 0\n",
    "\n",
    "data.dropna(subset=['text'], inplace=True)\n",
    "# If text column has null value, drop it\n",
    "\n",
    "\n",
    "data['text'] = data['text'].apply(remove_rt)\n",
    "# IF it has rt string, remove it. FOR RETWEETS only\n",
    "\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join(x.split()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23102926-ed81-4c94-841f-f579f707138f",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>DATASET AFTER PREPROCESSING</font>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb013678-4fae-47c1-87ed-cf098700aca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10               sa laki ng ginastos ni tapos sa laki din ng talo niya sa mayo siya pa din tameme sa ending ng kwento yun na\n",
      "11                 pet theory contrasted with pnoy for past years has not failed much then again he has not done much either\n",
      "12                                                                               sino ba si yuan nognog pandak laki sa hirap\n",
      "13                                                                                breaking vcm inside novotel cubao owned by\n",
      "14    di daw pagsisihan na binoto nila si mds kahit talo baka dun na kayo magsisi kung si or ang mananalo kayo na matatalino\n",
      "15                           so anak ni pala itong si will not be surprised if nese iye ne eng lehet will be campaign jingle\n",
      "16         ang kakapal ng mga mukha niyo pnoy at matapos niyong batikusin si at sila naman ang yayain niyo anu toh civil war\n",
      "17                                                                                               walang hindi importante kay\n",
      "18                            parang walang gustong maka tandem ni sa liberal party dahil alam nilang mahihirapang manalo si\n",
      "19                                                                     ok despite being bashed over tv interview via abs cbn\n",
      "20                                                                                       will definitely not vote for big no\n",
      "21                                                              si yung parang cartoon or anime na hindi nagpapalit ng damit\n",
      "22                                                             political ad on respect not response to rape remark clarifies\n",
      "23                                                                 is in naguilian isabela today to attend sectoral assembly\n",
      "24                                                                                     nakakairita na tong mga commercial ni\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['text'].iloc[10:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16338038-8ad1-4e72-b881-fce70efdb1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10192\n",
      "1     8685\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data.dropna(subset=['text'], inplace=True)\n",
    "# If text column has null value, drop it\n",
    "data.dropna(subset=['label'], inplace=True)\n",
    "# If text column has null value, drop it\n",
    "# Reset the index.\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "#Dataset after preprocessing\n",
    "data\n",
    "label_counts = data['label'].value_counts()\n",
    "print(label_counts)\n",
    "data\n",
    "# Drop null values.\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cca6b690-2d0e-464c-9b18-e5cee10ff86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in the 'text' column.\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].str.strip() != '']\n",
    "\n",
    "# Now, you can recheck if there are any missing values in the 'text' column\n",
    "if data['text'].isna().any():\n",
    "    print(\"There are still NA values in the 'text' column.\")\n",
    "else:\n",
    "    print(\"There are no missing values in the 'text' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56912734-3b2b-44f5-afeb-9ab3bf0be613",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>EXPORTING PREPROCESSED DATASET AS CSV</font>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59069eba-e1ee-4819-a0b9-9006a9857cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Testssss.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df031d-80c1-40f8-ba2b-3d98f7da13aa",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>PREPROCESSING DONE</font>\n",
    "## -------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvthesis",
   "language": "python",
   "name": "venvthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
