{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6666838-19ac-449e-a520-29deba50d92f",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032e9a9-2d9a-4cba-a91a-cf16977f32b3",
   "metadata": {},
   "source": [
    "# <span style=\"color:purple\">IMPORT LIBRARIES: ```</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb0dc4-056b-4858-9edd-6e2cc07c5a79",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6e89c807-ed95-4807-93b8-db4c1ff23761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b4d98-0213-4f91-a97a-e559a595bf4c",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <span style=\"color:purple\">IMPORT DATASET: ```</span>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5656e059-ddb2-4cf1-a5c5-883f1b4f3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"aaaa.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "74a45e07-6470-49ff-a0bc-a75bff9957d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #insert dataset\n",
    "# dataset = \"combinedV5\"\n",
    "\n",
    "# data = pd.read_csv(dataset+\".csv\",  )\n",
    "# #print(data['text'][:5])\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269ebf7-7b23-4a67-a2f4-8c0d4e530716",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------\n",
    "## <span style=\"color:purple\">DATASET Overview & Checking for NULL and DUPLICATE values ```</span>\n",
    "### -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "1903cd84-534d-47da-b4f6-8d1c4c6d20b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    10161\n",
      "1     8679\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gastos ni sa political ads halos p m na inaasahan na ni na may mga taong</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tang ina tuwid na daan daw eh sya nga di straight</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salamat sa walang sawang suporta ng mga taga makati ang pagbabalik in makati</td>\n",
       "      <td>0</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putangina mo takbo pa</td>\n",
       "      <td>1</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with selective amnesia forgetting about the past six years he spent preparing to be</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18835</th>\n",
       "      <td>if a hoe is talking to your man she is not the problem he is the fact that hoes feel welcomed reflects on how he acts behi</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18836</th>\n",
       "      <td>sounds like a bad bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18837</th>\n",
       "      <td>is that all pussy bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18838</th>\n",
       "      <td>i seen scooby hoe some niggas at the gardens too</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18839</th>\n",
       "      <td>this bitch just blew my high</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18840 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "0                                                        gastos ni sa political ads halos p m na inaasahan na ni na may mga taong   \n",
       "1                                                                               tang ina tuwid na daan daw eh sya nga di straight   \n",
       "2                                                    salamat sa walang sawang suporta ng mga taga makati ang pagbabalik in makati   \n",
       "3                                                                                                           putangina mo takbo pa   \n",
       "4                                             with selective amnesia forgetting about the past six years he spent preparing to be   \n",
       "...                                                                                                                           ...   \n",
       "18835  if a hoe is talking to your man she is not the problem he is the fact that hoes feel welcomed reflects on how he acts behi   \n",
       "18836                                                                                                     sounds like a bad bitch   \n",
       "18837                                                                                                     is that all pussy bitch   \n",
       "18838                                                                            i seen scooby hoe some niggas at the gardens too   \n",
       "18839                                                                                                this bitch just blew my high   \n",
       "\n",
       "       label  language  \n",
       "0          0   English  \n",
       "1          1   English  \n",
       "2          0  Filipino  \n",
       "3          1  Filipino  \n",
       "4          0   English  \n",
       "...      ...       ...  \n",
       "18835      1   English  \n",
       "18836      1   English  \n",
       "18837      1   English  \n",
       "18838      1   English  \n",
       "18839      1   English  \n",
       "\n",
       "[18840 rows x 3 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = data['label'].value_counts()\n",
    "print(label_counts)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ceb9ad78-a34c-415f-bf37-259c9f5e6b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18840 entries, 0 to 18839\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      18840 non-null  object\n",
      " 1   label     18840 non-null  int64 \n",
      " 2   language  18840 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 441.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#DATASET OVERVIEW\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "48f093c3-6f0a-4ea7-af05-bb93377a4c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label, language]\n",
       "Index: []"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK FOR NULL VALUES\n",
    "data.isnull().sum()\n",
    "null_rows = data[data['label'].isnull()]\n",
    "\n",
    "null_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "847ae30e-25fa-45a6-8b36-dbc409486ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK FOR DUPLICATE VALUES\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d081736-b61b-4200-9bd8-e5ec1850055c",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>Dropping Duplicates and NULL</font>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "747afc44-fe23-429b-8c00-d2cbb610bac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>okay nga si nalang kesa si o ano</td>\n",
       "      <td>0</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>bakit si ayaw pumunta di lang kasi boo abutin niya go</td>\n",
       "      <td>1</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>bakit si ayaw pumunta di lang kasi boo abutin niya go</td>\n",
       "      <td>1</td>\n",
       "      <td>Filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>supreme court upholds ca decision on junjun is case cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>completes senate slate</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18359</th>\n",
       "      <td>nigger</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>niggers</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18535</th>\n",
       "      <td>fag</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18564</th>\n",
       "      <td>fuck you faggot</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18616</th>\n",
       "      <td>fags</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          text  label  \\\n",
       "381                           okay nga si nalang kesa si o ano      0   \n",
       "485      bakit si ayaw pumunta di lang kasi boo abutin niya go      1   \n",
       "629      bakit si ayaw pumunta di lang kasi boo abutin niya go      1   \n",
       "787    supreme court upholds ca decision on junjun is case cnn      0   \n",
       "1025                                    completes senate slate      0   \n",
       "...                                                        ...    ...   \n",
       "18359                                                   nigger      1   \n",
       "18450                                                  niggers      1   \n",
       "18535                                                      fag      1   \n",
       "18564                                          fuck you faggot      1   \n",
       "18616                                                     fags      1   \n",
       "\n",
       "       language  \n",
       "381    Filipino  \n",
       "485    Filipino  \n",
       "629    Filipino  \n",
       "787     English  \n",
       "1025    English  \n",
       "...         ...  \n",
       "18359   English  \n",
       "18450   English  \n",
       "18535   English  \n",
       "18564   English  \n",
       "18616   English  \n",
       "\n",
       "[800 rows x 3 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Duplicates\n",
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a8579702-411a-4cc9-a862-94405c7b21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicates.\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop null values.\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Reset the index.\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "4189afc8-ee34-4ff8-88e0-5824835e5b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if there are still duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9f9a0b33-685f-4962-ac82-07495994ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        0\n",
       "label       0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if there are still NULL values\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf47f4e-bd92-48a0-be8e-ac93add621b7",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <span style=\"color:purple\">Data Preprocessing Functions ```</span>\n",
    "## <font color='purple'>``` Functions Overview ```</font>\n",
    "1. **<font color='blue'>Lowercasing</font>**\n",
    "2. **<font color='blue'>Binary Classification</font>**\n",
    "3. **<font color='blue'>Data De-identification</font>**\n",
    "4. **<font color='blue'>Hashtag Removal</font>**\n",
    "5. **<font color='blue'>URL Removal</font>**\n",
    "6. **<font color='blue'>Removing Numbers</font>**\n",
    "7. **<font color='blue'>Removing Extra White Space</font>**\n",
    "8. **<font color='blue'>Contraction Expansion</font>**\n",
    "9. **<font color='blue'>Punctuation Removal</font>**\n",
    "10. **<font color='blue'>Stop Words Removal</font>**\n",
    "11. **<span style=\"color:blue\">Candidate Names and RT String Removal</span>**\n",
    "## -------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "3c055cef-bb9f-4b70-97c6-732aa317f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercasing\n",
    "def lowercasing(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "    return text\n",
    "\n",
    "#binary classification of Hate Score \n",
    "def binary_classification(num):\n",
    "    if isinstance(num, str):\n",
    "        num = float(num)  # Convert num to float if it's a string\n",
    "    if num >= 0.5:\n",
    "        num = 1\n",
    "    else:\n",
    "        num = 0\n",
    "    return num\n",
    "\n",
    "# Remove Mentions - Data-deidentification\n",
    "def data_deidentification(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'@\\w+\\:?', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'#\\w+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_urls(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'https?://\\S+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'\\d+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'\\s+', ' ', text.strip())\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8d897aa2-1037-49ec-a2a9-9604fc5c734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contraction library\n",
    "def contraction_expansion(text):\n",
    "    contractions = { \n",
    "        \"won't\": \"will not\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"what's\": \"what is\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"%\": \" percent\",\n",
    "        \"that's\": \"that is\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"he's\": \"he is\",\n",
    "        \"she's\": \"she is\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"n't\": \" not\",\n",
    "        \"'ve\": \" have\",\n",
    "        \"'s\": \" is\",\n",
    "        \"’s\": \"\",\n",
    "        \"'re\": \" are\",\n",
    "        \"'d\": \" would\",\n",
    "        \"'ll\": \" will\",\n",
    "        \"'m\": \" am\"\n",
    "    }\n",
    "    for contraction, replacement in contractions.items(): \n",
    "        text = text.replace(contraction, replacement)\n",
    "    return text\n",
    "    \n",
    "\n",
    "\n",
    "def punctuations_and_abbreviations(text):\n",
    "    library = [\n",
    "        (r\"w/\", \" with \"),\n",
    "        (r\"w/o\", \"without\"),\n",
    "        (r\"(\\d+)(k)\", r\"\\g<1>000\"),\n",
    "        (r\":\", \" : \"),\n",
    "        (r\" u s \", \" american \"),\n",
    "        (r\"\\0s\", \"0\"),\n",
    "        (r\" 9 11 \", \"911\"),\n",
    "        (r\"e - mail\", \"email\"),\n",
    "        (r\"j k\", \"jk\"),\n",
    "        (r\"\\s{2,}\", \" \"),\n",
    "        (r\"amp;\", \"and\"),\n",
    "        (r\"g2g\", \"gtg\"),\n",
    "        (r\"2moro\", \"tomorrow\"),\n",
    "        (r\"b4\", \"before\"),\n",
    "        (r\"2nite\", \"tonight\"),\n",
    "        (r\"2day\", \"today\"),\n",
    "        (r\"4U\", \"for you\"),\n",
    "        (r\"4get\", \"forget\"),\n",
    "        (r\"2morrow\", \"tomorrow\"),\n",
    "        (r\"2be\", \"because\"),\n",
    "        (r\"l8r\", \"later\"),\n",
    "        (r\",\", \" \"),\n",
    "        (r\"\\.\", \" \"),\n",
    "        (r\"!\", \" \"),\n",
    "        (r\";\", \" \"),\n",
    "        (r\"-\", \" \"),\n",
    "        (r\":\", \" \"),\n",
    "        (r\"\\/\", \" \"),\n",
    "        (r\"%\", \" \"),\n",
    "        (r\"&\", \" \"),\n",
    "        (r\"\\^\", \" ^ \"),\n",
    "        (r\"\\+\", \" + \"),\n",
    "        (r\"\\-\", \" - \"),\n",
    "        (r\"\\=\", \" = \"),\n",
    "        # (r\"'\", \" \"),\n",
    "        (r\"[^A-Za-z0-9^,!.\\/+-=]\", \" \"), \n",
    "    ]\n",
    "    for pattern, replacement in library:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#From Filipino Toxic Speech\n",
    "# Built-in English stop words.\n",
    "# english_stop_words = CountVectorizer(stop_words='english').get_stop_words()\n",
    "\n",
    "def custom_stop_words():\n",
    "    custom_stop_words = [\n",
    "        'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and',\n",
    "        'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being',\n",
    "        'below', 'between', 'both', 'but', 'by', 'can', \"can't\", 'cannot', 'could',\n",
    "        \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down',\n",
    "        'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has',\n",
    "        \"hasn't\", 'have', \"haven't\", 'having', 'how', \"how's\", \"see\",\n",
    "         \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", \n",
    "        \"it's\", 'its', 'itself', \"let's\", 'more', 'most', \"mustn't\", \n",
    "        'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other',\n",
    "        'ought', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", \n",
    "        'should', \"shouldn't\", 'so', 'some', 'such', 'than',\n",
    "        'that', \"that's\", 'the', 'theirs', 'then', 'there',\n",
    "        \"there's\", 'these',  'this',\n",
    "        'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\",\n",
    "        'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\",\n",
    "        'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom',\n",
    "        'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\",\"just\",\"will\",\"like\", \"know\", \"say\",\"says\",\"it\",\"get\",\n",
    "        \"makes\",\"make\",\"me\",\"till\", \"end\"\n",
    "        # filipino_stop_words1    \n",
    "        \"ako\", \"akin\", \"ako'y\", \"amin\", \"aming\", \"ang\", \"ano\", \"anuman\", \"apat\", \"at\", \"atin\", \"ating\",\n",
    "        \"ay\", \"bababa\", \"bago\", \"bakit\", \"bawat\", \"bilang\", \"dahil\", \"dalawa\", \"dapat\", \"din\", \"dito\", \"doon\",\n",
    "        \"gagawin\", \"gayunman\", \"ginagawa\", \"ginawa\", \"ginawang\", \"gumawa\", \"gusto\", \"habang\", \"hanggang\", \"hindi\", \"huwag\", \"iba\",\n",
    "        \"ibaba\", \"ibabaw\", \"ibig\", \"ilagay\", \"ilalim\", \"ilan\", \"inyong\", \"isa\", \"isang\", \"ito\", \"iyo\",\n",
    "        \"iyon\", \"iyong\", \"kahit\", \"kailangan\", \"kailanman\", \"kami\", \"kanila\", \"kanilang\", \"kanino\", \"kanya\", \"kanyang\",\n",
    "        \"kapag\", \"kapwa\", \"karamihan\", \"katiyakan\", \"katulad\", \"kay\", \"kaya\", \"kaysa\", \"ko\", \"kung\", \"laban\",\n",
    "        \"lahat\", \"lamang\", \"likod\", \"lima\", \"maaari\", \"maaaring\", \"maging\", \"mahusay\", \"makita\", \"marami\", \"marapat\", \"mga\",\n",
    "        \"minsan\", \"mismo\", \"mula\", \"muli\", \"na\", \"nabanggit\", \"naging\", \"nagkaroon\", \"nais\", \"nakita\", \"namin\", \"napaka\",\n",
    "        \"narito\", \"nasaan\", \"ng\", \"nga\", \"ngayon\", \"ni\", \"nila\", \"nilang\", \"nito\", \"niyang\", \"noon\",\n",
    "        \"o\", \"pag\", \"pala\", \"para\", \"pati\", \"pero\", \"pumunta\", \"pumupunta\", \"sa\", \"saan\", \"sabi\", \"sabihin\",\n",
    "        \"sarili\", \"sino\", \"tatlo\", \"tayo\", \"tulad\", \"tungkol\", \"una\", \"walang\",\n",
    "        #filipino_stopwords2 \n",
    "        'ako', 'sa', 'akin', 'ko', 'aking', 'sarili', 'kami', 'atin', 'ang', 'aming', 'amin', 'ating',\n",
    "        'ka', 'iyong', 'iyo', 'inyong', 'kanya', 'mismo', 'ito', 'nito', 'kanyang', 'nila',\n",
    "        'kanila', 'kanilang', 'kung', 'ano', 'alin', 'sino', 'kanino', 'na', 'mga', 'iyon', 'am', 'ay',\n",
    "        'maging', 'naging', 'mayroon', 'may', 'nagkaroon', 'pagkakaroon', 'gumawa', 'ginagawa', 'ginawa', 'paggawa',\n",
    "        'ibig', 'dapat', 'maaari', 'marapat', 'kong', 'tayo', 'hindi', 'namin', 'gusto', 'nais',\n",
    "        'niyang', 'nilang', 'huwag', 'ginawang', 'gagawin', 'maaaring', 'sabihin', 'narito', 'kapag', 'ni',\n",
    "        'nasaan', 'bakit', 'paano', 'kailangan', 'walang', 'katiyakan', 'isang', 'at', 'pero', 'o', 'dahil',\n",
    "        'bilang', 'hanggang', 'habang', 'ng', 'pamamagitan', 'para', 'tungkol', 'laban', 'pagitan', 'panahon', 'bago',\n",
    "        'pagkatapos', 'itaas', 'ibaba', 'mula', 'pataas', 'pababa', 'palabas', 'ibabaw', 'ilalim', 'muli', 'pa',\n",
    "        'minsan', 'dito', 'doon', 'saan', 'lahat', 'anumang', 'kapwa', 'bawat', 'ilan', 'karamihan', 'iba', 'tulad',\n",
    "        'lamang', 'pareho', 'kaya', 'kaysa', 'masyado', 'napaka', 'isa', 'bababa', 'kulang', 'marami', 'ngayon',\n",
    "        'kailanman', 'sabi', 'nabanggit', 'din', 'kumuha', 'pumunta', 'pumupunta', 'ilagay', 'makita', 'nakita',\n",
    "        'katulad', 'mahusay', 'likod', 'kahit', 'paraan', 'noon', 'gayunman', 'dalawa', 'tatlo', 'apat', 'lima',\n",
    "        'una', 'pangalawa',\n",
    "\n",
    "        #filipino_stopwords3\n",
    "        'wag','lang', 'di','naman', 'nalang','lang', 'ba','wala', \"si\", \"pagbabalik\", \"makati\", \"talaga\",\"mas\",\"mataas\", \"yan\"\n",
    "        #some shit\n",
    "         \"you you\", \"tsk tsk\", \"tsk\",\"tell\", \"every\",\"commercial\", \"thank\", \"income\", \"tax\", \"guys\", \"party\", \"liberal\", \"place\",\n",
    "        #some\n",
    "        \"abs\", \"cbn\", \"bandila\", \"gma\", \"inquirer\", \"rappler\", \"via\", \"ad\", \"ph\", \"vote\", \"tv\",\"ads\", \"black\", \"propaganda\", \"look\",\"partial\", \n",
    "        \"unofficial\", \"country\",\"presidential\", \"candidate\",\"happy\", \"birthday\",\n",
    "\n",
    "        #eng\n",
    "        \"right\",\"now\", \"think\", \"our\"\n",
    " \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    ]\n",
    "    return custom_stop_words\n",
    "\n",
    "def remove_custom_stopwords(text):\n",
    "    custom_stopwords = custom_stop_words()\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    # Remove custom stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in custom_stopwords]\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "803b0e89-34e9-4cd6-be36-6a4cfac30840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_candidate_name(text):\n",
    "    candidate = { \n",
    "    \"rodrigo\": \" \",\n",
    "    \"'roa\": \" \",\n",
    "    \"duterte\": \" \",\n",
    "    \"du30\": \"what is \",\n",
    "    \"prrd\": \" \", \n",
    "    \"rody\": \" \",\n",
    "    \"digong\": \" \", \n",
    "    \"alan\": \" \", \n",
    "    \"peter\": \" \", \n",
    "    \"cayetano\": \" \", \n",
    "    \"apc\": \" \",\n",
    "    \"mar\": \" \", \n",
    "    \"roxas\": \" \", \n",
    "    \"robredo\": \" \", \n",
    "    \"leni\": \" \",\n",
    "    \"poe\": \" \", \n",
    "    \"grace\": \" \",\n",
    "    \"escudero\": \" \", \n",
    "    \"chiz\": \" \", \n",
    "    \"francis\": \" \",\n",
    "    \"binay\": \" \", \n",
    "    \"jojo\": \" \", \n",
    "    \"vice\": \" \", \n",
    "    \"jejomar\": \" \", \n",
    "    \"honasan\": \" \", \n",
    "    \"gringo\": \" \", \n",
    "    \"gregorio\": \" \",\n",
    "    \"vp\": \" \", \n",
    "    \"president\": \" \", \n",
    "    \"senator\": \" \",\n",
    "    \"daniel\": \" \",\n",
    "    \"padilla\": \" \",\n",
    "    \"abi\": \" \",\n",
    "    \"charlie\": \" \",\n",
    "    \"sheen\": \" \",\n",
    "    \"sen\": \" \",\n",
    "    \"miriam\": \" \",\n",
    "    \"abi\": \" \",\n",
    "    \"abby\": \" \",\n",
    "    \"zapanta\": \" \",\n",
    "\n",
    "       \n",
    "    \n",
    "    \n",
    "    }\n",
    "    # Replace candidate names\n",
    "    for name, replacement in candidate.items():\n",
    "        text = re.sub(r'\\b' + re.escape(name) + r'\\b', replacement, text)\n",
    "    return text\n",
    "\n",
    "def remove_rt_and_single_char(text):\n",
    "    if isinstance(text, str):\n",
    "        pattern = r'\\brt\\b|\\b[a-z]\\b'\n",
    "        return re.sub(pattern, '', text.strip())\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36399685-d27b-4e94-824c-45711ad7842c",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>Applying Preprocessing to Data</font>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "d69523b7-c461-4489-84e7-b3187c90358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['text'] = data['text'].apply(remove_extra_spaces)\n",
    "#data\n",
    "#data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "b1a59b91-2a91-4798-89d9-a281e482758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample text: \n",
    "#@jejomarbinay Sana ako na lang yung napili sa THE VOICE      #thevoice. DUTERTE and CAYETANO WON! it's 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(lowercasing)\n",
    "# @jejomarbinay sana ako na lang yung napili sa the voice      #thevoice. duterte won! it's 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(remove_extra_spaces)\n",
    "# sana ako na lang yung napili sa the voice #thevoice. duterte and cayetano won! it's 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(data_deidentification)\n",
    "# sana ako na lang yung napili sa the voice #thevoice. duterte and cayetano won! it's 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(contraction_expansion)\n",
    "# sana ako na lang yung napili sa the voice #thevoice. duterte and cayetano won! it is 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(remove_candidate_name)\n",
    "# sana ako na lang yung napili sa the voice #thevoice. won! it is 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(remove_rt_and_single_char)\n",
    "# IF it has rt string, remove it. FOR RETWEETS only\n",
    "\n",
    "data['text'] = data['text'].apply(remove_hashtags)\n",
    "# sana ako na lang yung napili sa the voice. won! it is 100% unfair voting ... https://debololo.com\n",
    "\n",
    "data['text'] = data['text'].apply(remove_urls)\n",
    "# sana ako na lang yung napili sa the voice. won! it is 100% unfair voting ...\n",
    "\n",
    "data['text'] = data['text'].apply(punctuations_and_abbreviations)\n",
    "# sana ako na lang yung napili sa the voice won it is 100 unfair voting\n",
    "\n",
    "data['text'] = data['text'].apply(remove_numbers)\n",
    "# sana ako na lang yung napili sa the voice. won! it is unfair voting ...\n",
    "\n",
    "data['text'] = data['text'].apply(remove_custom_stopwords)\n",
    "\n",
    "# sana lang yung napili voice. won unfair voting\n",
    "\n",
    "data['label'] = data['label'].apply(binary_classification)\n",
    "# Assuming hate label for the sample text is 0.3, it is converted to 0\n",
    "\n",
    "data.dropna(subset=['text'], inplace=True)\n",
    "# If text column has null value, drop it\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join(x.split()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23102926-ed81-4c94-841f-f579f707138f",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>DATASET AFTER PREPROCESSING</font>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "bb013678-4fae-47c1-87ed-cf098700aca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000                                                                        pm pdplbn ind\n",
      "10001                          srsly though whatever you still philippines you respect him\n",
      "10002                                 using children political winning mr you call decency\n",
      "10003                               yung famewhore mong classmate mahilig manira ibang tao\n",
      "10004                                                                                     \n",
      "                                               ...                                        \n",
      "18035    hoe talking your man she problem he fact hoes feel welcomed reflects he acts behi\n",
      "18036                                                                     sounds bad bitch\n",
      "18037                                                                          pussy bitch\n",
      "18038                                                       seen scooby hoe niggas gardens\n",
      "18039                                                                   bitch blew my high\n",
      "Name: text, Length: 8040, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['text'].iloc[10000:21000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "16338038-8ad1-4e72-b881-fce70efdb1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    9539\n",
      "1    8501\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data.dropna(subset=['text'], inplace=True)\n",
    "# If text column has null value, drop it\n",
    "data.dropna(subset=['label'], inplace=True)\n",
    "# If text column has null value, drop it\n",
    "# Reset the index.\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "#Dataset after preprocessing\n",
    "data\n",
    "label_counts = data['label'].value_counts()\n",
    "print(label_counts)\n",
    "data\n",
    "# Drop null values.\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "cca6b690-2d0e-464c-9b18-e5cee10ff86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                    text  \\\n",
      "0                                                 gastos political halos inaasahan taong   \n",
      "1                                                tang ina tuwid daan daw eh sya straight   \n",
      "2                                                            salamat sawang suporta taga   \n",
      "4                         selective amnesia forgetting past six years he spent preparing   \n",
      "5                             matter whoever won long they finally changed noynoy failed   \n",
      "...                                                                                  ...   \n",
      "18033                                                        hmu you stop bein lil bitch   \n",
      "18034                                              money bitches bc bitches follow money   \n",
      "18035  hoe talking your man she problem he fact hoes feel welcomed reflects he acts behi   \n",
      "18038                                                     seen scooby hoe niggas gardens   \n",
      "18039                                                                 bitch blew my high   \n",
      "\n",
      "       label  language  \n",
      "0          0   English  \n",
      "1          1   English  \n",
      "2          0  Filipino  \n",
      "4          0   English  \n",
      "5          0   English  \n",
      "...      ...       ...  \n",
      "18033      1   English  \n",
      "18034      1   English  \n",
      "18035      1   English  \n",
      "18038      1   English  \n",
      "18039      1   English  \n",
      "\n",
      "[14872 rows x 3 columns]\n",
      "There are no missing values in the 'text' column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JayProkz\\AppData\\Local\\Temp\\ipykernel_9480\\2793800475.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop('word_count', axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# data['word_count'] = data['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# # Drop rows where the word count is less than or equal to 1\n",
    "# data = data[data['word_count'] > 3]\n",
    "\n",
    "# # Drop the 'word_count' column as it's no longer needed\n",
    "# data.drop('word_count', axis=1, inplace=True)\n",
    "\n",
    "# # Display the DataFrame after dropping rows with one term or one word in the 'text' column\n",
    "# print(data)\n",
    "\n",
    "# data = data[data['text'].str.strip() != '']\n",
    "\n",
    "# # Now, you can recheck if there are any missing values in the 'text' column\n",
    "# if data['text'].isna().any():\n",
    "#     print(\"There are still NA values in the 'text' column.\")\n",
    "# else:\n",
    "#     print(\"There are no missing values in the 'text' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56912734-3b2b-44f5-afeb-9ab3bf0be613",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>EXPORTING PREPROCESSED DATASET AS CSV</font>\n",
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "59069eba-e1ee-4819-a0b9-9006a9857cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('latestPre.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df031d-80c1-40f8-ba2b-3d98f7da13aa",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------\n",
    "# <font color='purple'>PREPROCESSING DONE</font>\n",
    "## -------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
